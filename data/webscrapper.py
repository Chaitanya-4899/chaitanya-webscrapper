# -*- coding: utf-8 -*-
"""WebScrapper.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1swnGpxtELGt12tpPEOg1M7YdAn7PdEVy
"""

import requests
from bs4 import BeautifulSoup as bs
import pandas as pd
import csv

URL = ['https://www.contractsfinder.service.gov.uk/Search/Results'
      ,'https://www.contractsfinder.service.gov.uk/Search/Results?&page=125#dashboard_notices']
 
for url in range(0,1):
  req = requests.get(URL[url])
  soup = bs(req.text, 'html.parser')
 
contracts=soup.find_all('div', attrs={'class', 'search-result-header'})
contractby=soup.find_all('div', attrs={'class', 'search-result-sub-header wrap-text'})
contractdetails=soup.find_all('div',attrs={'class','wrap-text'})

contractName = []
for c in contracts:
  d= c.text.replace('\n','')
  contractName.append(d)

contractBY = []
for cb in contractby:
  d= cb.text
  contractBY.append(d)

df = pd.DataFrame({'Contract Name':contractName,'Contract Given By':contractBY})
df.to_csv('UKcontract.csv', index=True, index_label='Contract_ID', encoding='utf-8')